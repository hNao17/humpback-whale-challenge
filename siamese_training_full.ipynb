{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"siamese_train.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"A4pq_tDukMYb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import cv2 as cv\n","import matplotlib.pyplot as plt\n","import math\n","import numpy as np\n","import random\n","import pandas as pd\n","import pickle\n","import os\n","\n","import keras.utils\n","from keras import backend as K\n","\n","from keras.applications import mobilenet, resnet50, inception_resnet_v2, inception_v3, vgg16\n","from keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import dot, Dropout, Dense, GlobalAveragePooling2D, Input, Lambda\n","from keras.models import Model\n","from keras.optimizers import RMSprop\n","from keras.regularizers import l2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NTWon4JLkMYs","colab_type":"text"},"cell_type":"markdown","source":["## Load Training / Validation Encodings"]},{"metadata":{"id":"IVvMCzYLkMYz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with open('x_train_pairs_vgg.pickle', 'rb') as f:\n","    x_train_encoding = pickle.load(file=f)\n","\n","with open('x_val_pairs_vgg.pickle', 'rb') as f:\n","    x_val_encoding = pickle.load(file=f)\n","\n","print(\"x_train encodings: \" + str(x_train_encoding.shape))\n","print(\"x_val encodings: \" + str(x_val_encoding.shape))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CnVaUClkkMZI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def create_labels(n_labels):\n","    \n","    y = []\n","    \n","    for i in range(0,n_labels):\n","        if i%2==0: \n","            y.append(1)\n","        else:\n","            y.append(0)\n","            \n","    return np.array(y, np.int)\n","\n","y_train = create_labels(x_train_encoding.shape[0])\n","y_val = create_labels(x_val_encoding.shape[0])\n","print(\"y_train: \"+str(y_train.shape))\n","print(\"y_val: \"+str(y_val.shape))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FfRDyIZ9kMZU","colab_type":"text"},"cell_type":"markdown","source":["## Define Siamese Model"]},{"metadata":{"id":"WZNOIsd4kMZZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# calculate cosine distance b/t feature vector outputs from base network\n","def cos_distance(feat_vects):\n","\n","    K.set_epsilon(1e-07)\n","    epsilon = K.epsilon()\n","\n","    x1, x2 = feat_vects\n","\n","    result = K.maximum(x=dot(inputs=[x1, x2], axes=1, normalize=True), y=epsilon)\n","\n","    return result\n"," \n","# calculate l1_norm b/t feature vector outputs from base network\n","def l1_distance(feat_vects):\n","\n","    x1, x2 = feat_vects\n","\n","    result = K.maximum(x=K.sum(x=K.abs(x1-x2), axis=1, keepdims=True), y=epsilon)\n","\n","    return result\n"," \n","\n","# calculate l2_distance b/t feature vector outputs from base network\n","def l2_distance(feat_vects):\n","\n","    x1, x2 = feat_vects\n","\n","    result = K.sqrt(K.maximum(x=K.sum(x=K.square(x1 - x2), axis=1, keepdims=True), y=epsilon))\n","\n","    return result\n","\n","\n","# create a siamese model that calculates similarity b/t two feature vectors\n","def create_siamese_model(encoding_shape, similarity_metric):\n","\n","    encoding_a = Input(shape=encoding_shape, name='encoding_a')\n","    encoding_b = Input(shape=encoding_shape, name='encoding_b')\n","    \n","    # encoding_a = Dropout(rate=0.6)(encoding_a)\n","    # encoding_b = Dropout(rate=0.6)(encoding_b)\n","\n","    fc1_a = Dense(units=2048, activation='relu', kernel_regularizer=l2(l=0.0000), name='fc1_a')(encoding_a)\n","    fc1_b = Dense(units=2048, activation='relu', kernel_regularizer=l2(l=0.0000), name='fc1_b')(encoding_b)\n","\n","    # fc1_a = Dropout(rate=0.3)(fc1_a)\n","    # fc1_b = Dropout(rate=0.3)(fc1_b)\n","\n","    if similarity_metric == 'cosine':\n","      distance = Lambda(function=cos_distance, name='cos_distance')([fc1_a, fc1_b])\n","      \n","    elif similarity_metric == 'l1':\n","      distance == Lambda(function=l1_distance, name='l1_distance')([fc1_a, fc1_b])\n","      \n","    elif similarity_metric == 'l2':\n","      distance == Lambda(function=l2_distance, name='l2_distance')([fc1_a, fc1_b])\n","\n","    prediction = Dense(units=1, activation='sigmoid', kernel_regularizer=l2(l=0.0000), name='sigmoid')(distance)\n","\n","    model = Model(inputs=[encoding_a, encoding_b], outputs=prediction, name='siamese_model')\n","\n","    return model\n","\n","# create siamese model\n","encoding_shape = x_train_encoding.shape[2:]\n","print(encoding_shape)\n","\n","cosine_model = create_siamese_model(encoding_shape, 'cosine')\n","print(cosine_model.summary())\n","\n","l1_model = create_siamese_model(encoding_shape, 'l1')\n","print(l1_model.summary())\n","\n","l2_model = create_siamese_model(encoding_shape, 'l2')\n","print(l2_model.summary())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k4V_AfJEkMZp","colab_type":"text"},"cell_type":"markdown","source":["## Training"]},{"metadata":{"id":"GKz11oNKkMZq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def step_decay_schedule(lr_initial=0.001, decay=0.75, step_size=10):\n","    def schedule(epoch):\n","        return lr_initial * math.pow(decay, math.floor((1 + epoch) / step_size))\n","\n","    return LearningRateScheduler(schedule=schedule, verbose=1)\n","\n","\n","def get_lr_metric(optimizer):\n","    def lr(y_true, y_pred):\n","        return optimizer.lr\n","\n","    return lr\n","\n","\n","def create_callbacks(lr_type, wts_fn, enable_early_stopping=False, enable_save_wts=False):\n","    cbks = []\n","\n","    # learning rate\n","    if lr_type is 0:\n","        lr_schedule = step_decay_schedule()\n","        cbks.append(lr_schedule)\n","\n","    elif lr_type is 1:\n","        reduce_lr_schedule = ReduceLROnPlateau(monitor='val_loss',\n","                                               factor=0.75,\n","                                               patience=10,\n","                                               min_lr=1e-6,\n","                                               verbose=1)\n","        cbks.append(reduce_lr_schedule)\n","\n","    # early stopping\n","    if enable_early_stopping is True:\n","        early_stopper = EarlyStopping(monitor='val_loss', patience=10)\n","        cbks.append(early_stopper)\n","\n","    # model checkpoint\n","    if enable_save_wts is True:\n","        # save_dir = '/artifacts' /artifacts\n","        wts = wts_fn\n","        model_chpt = ModelCheckpoint(filepath=wts,\n","                                     monitor='val_loss',\n","                                     verbose=1,\n","                                     save_weights_only=True,\n","                                     save_best_only=False,\n","                                     period=10)\n","\n","        cbks.append(model_chpt)\n","\n","    return cbks\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K02aPZ9sn99k","colab_type":"text"},"cell_type":"markdown","source":["### Cosine"]},{"metadata":{"id":"wTMdjhaZoAd-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# create callbacks\n","lr_type = 3  # 0=step decay, 1=val_loss decay\n","cosine_cbks = create_callbacks(lr_type, 'traingen_wts7.h5', False, True)\n","\n","# training setup\n","batch_size = 32\n","n_epochs = 20\n","optim = RMSprop(lr=1e-2)\n","lr_metric = get_lr_metric(optim)\n","\n","cosine_model.compile(loss=\"binary_crossentropy\", optimizer=optim, metrics=['accuracy',lr_metric])\n","# K.clear_session()\n","\n","print(x_train_encoding[:, 1].shape)\n","hist_cosine = cosine_model.fit(x=[x_train_encoding[:, 0], x_train_encoding[:, 1]],\n","                               y=y_train,\n","                               batch_size=batch_size,\n","                               epochs=n_epochs,\n","                               validation_data=([x_val_encoding[:, 0], x_val_encoding[:, 1]], y_val),\n","                               shuffle=True,\n","                               verbose=1,\n","                               callbacks=cosine_cbks)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l6aUObcuoiip","colab_type":"text"},"cell_type":"markdown","source":["### L1 Norm"]},{"metadata":{"id":"hocXoIfmok4R","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# create callbacks\n","lr_type = 3  # 0=step decay, 1=val_loss decay\n","l1_cbks = create_callbacks(lr_type, 'traingen_wts8.h5', False, True)\n","\n","# training setup\n","batch_size = 32\n","n_epochs = 20\n","optim = RMSprop(lr=1e-2)\n","lr_metric = get_lr_metric(optim)\n","\n","l1_model.compile(loss=\"binary_crossentropy\", optimizer=optim, metrics=['accuracy',lr_metric])\n","# K.clear_session()\n","\n","print(x_train_encoding[:, 1].shape)\n","hist_l1 = l1_model.fit(x=[x_train_encoding[:, 0], x_train_encoding[:, 1]],\n","                          y=y_train,\n","                          batch_size=batch_size,\n","                          epochs=n_epochs,\n","                          validation_data=([x_val_encoding[:, 0], x_val_encoding[:, 1]], y_val),\n","                          shuffle=True,\n","                          verbose=1,\n","                          callbacks=cosine_cbks)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jxp1m2Mwo6Jm","colab_type":"text"},"cell_type":"markdown","source":["### L2 Norm"]},{"metadata":{"id":"xEjMbWYlo6p2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# create callbacks\n","lr_type = 3  # 0=step decay, 1=val_loss decay\n","l2_cbks = create_callbacks(lr_type, 'traingen_wts9.h5', False, True)\n","\n","# training setup\n","batch_size = 32\n","n_epochs = 20\n","optim = RMSprop(lr=1e-2)\n","lr_metric = get_lr_metric(optim)\n","\n","l2_model.compile(loss=\"binary_crossentropy\", optimizer=optim, metrics=['accuracy',lr_metric])\n","# K.clear_session()\n","\n","print(x_train_encoding[:, 1].shape)\n","hist_l2 = l2_model.fit(x=[x_train_encoding[:, 0], x_train_encoding[:, 1]],\n","                          y=y_train,\n","                          batch_size=batch_size,\n","                          epochs=n_epochs,\n","                          validation_data=([x_val_encoding[:, 0], x_val_encoding[:, 1]], y_val),\n","                          shuffle=True,\n","                          verbose=1,\n","                          callbacks=cosine_cbks)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LAvxWB4OkMZ9","colab_type":"text"},"cell_type":"markdown","source":["## Plot Training Metrics"]},{"metadata":{"id":"JHnxcptekMaB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def plot_training_metrics(title, x_axis_label, y_axis_label, y, x=None):\n","    \n","    if x is None:\n","        plt.plot(y[0])\n","        plt.plot(y[1])\n","    else:\n","        plt.plot(x,y[0])\n","        plt.plot(x,y[1])\n","    \n","    plt.title(title)\n","    plt.ylabel(y_axis_label)\n","    plt.xlabel(x_axis_label)\n","    plt.legend(['train', 'val'], loc='upper right')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xu981wX4kMaI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Loss vs. epochs - Cosine\n","plot_training_metrics(title='Model Loss',x_axis_label='Epoch',y_axis_label='Loss',\n","                     y=[hist_cosine.history['loss'], hist_cosine.history['val_loss']])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XAJ2-QMXkMaX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Loss vs. epochs - L1 Norm\n","plot_training_metrics(title='Model Loss',x_axis_label='Epoch',y_axis_label='Loss',\n","                     y=[hist_l1.history['loss'], hist_l1.history['val_loss']])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Uvl-xo9Arbh7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Loss vs. epochs - L2 Norm\n","plot_training_metrics(title='Model Loss',x_axis_label='Epoch',y_axis_label='Loss',\n","                     y=[hist_l2.history['loss'], hist_l2.history['val_loss']])"],"execution_count":0,"outputs":[]}]}